---
title: "Homework 4"
author: "David Rodden"
date: "March 6, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("Lock5withR", lib.loc="~/R/win-library/3.3")
library("mosaic", lib.loc="~/R/win-library/3.3")
```

###5.40
```{r}
old.mu = 62; old.sigma = 18
studentA.old_score = 47
studentB.old_score = 90
studentA.z = (studentA.old_score - old.mu)/old.sigma
studentB.z = (studentB.old_score - old.mu)/old.sigma
studentA.z; studentB.z

new.mu = 75; new.sigma = 10
studentA.new_score = new.mu + studentA.z * new.sigma
studentB.new_score = new.mu + studentB.z * new.sigma
studentA.new_score; studentB.new_score
```

The new scores of the students who scored 47 and 90 would earn `r round(studentA.new_score, 2)` and `r round(studentB.new_score, 2)` respectively.

###5.41

*(a)*
```{r}
mean = 100; st_dev = 20
z.lower = (60 - 100)/20; z.upper = (140 - 100)/20
area.between = pnorm(2) - pnorm(-2)
xpnorm(c(-2, 2))
```
The area between `r z.lower ` and `r z.upper` is `r area.between`, which is greater than 0.95, so this has been verified.

*(b)*

The proportion of values that fall within one standard deviation of the mean would be the area between -1 & 1 on a standard normal curve.
```{r}
area.between = pnorm(1) - pnorm(-1)
xpnorm(c(-1, 1))
```
The area given is `r area.between`.

*(c)*

The proportion of values that fall within three standard deviations of the mean would be the area between -3 & 3 on a standard normal curve.
```{r}
area.between = pnorm(3) - pnorm(-3)
xpnorm(c(-3, 3))
```
The area given is `r area.between`.

*(d)*

The answers to *(b)* and *(c)* would be the same as regardless of the normal distribution, z = $\pm 1, 3$ respectively for proportion of values that fall within one and three standard distributions.

###6.24

```{r}
flight.mean = 0.8
flight.stderr = sqrt(0.8*(1-0.8)/400)
```
Since the standard error of the flight equates to being only 0.2, it is not likely that the flights will be within 0.03 of the true population proportion.
Test

###6.48

```{r}
me = 0.3
z.star = qnorm(0.955)
estimate.conservative = 0.5
estimate.first = 0.7
estimate.second = 0.9
size.conservative = ceiling((z.star/me)^2 * estimate.conservative * (1 - estimate.conservative))
size.conservative
size.first = ceiling((z.star/me)^2 * estimate.first * (1 - estimate.first))
size.first
size.second = ceiling((z.star/me)^2 * estimate.second * (1 - estimate.second))
size.second
```
The sample size needed for instances $p = 0.5, 0.7, 0.9$ respectively with $95$% confidence and a margin of error within $\pm3$% are `r size.conservative`, `r size.first`, and `r size.second` respectively.
From the data observed above, we can see that with the elevation of our p estimate, the sample size needed to give decreases.

###6.54

```{r}
icu.status = ICUAdmissions$Status
icu.size = length(icu.status)
p.hat = sum(icu.status %in% 0)/icu.size; p.hat
z.star = qnorm(0.955)
se = sqrt(p.hat * (1 - p.hat)/icu.size); se
ci.lower = round(p.hat - z.star * se, 3)
ci.upper = round(p.hat + z.star * se, 3)
```
The confidence interval for the proportion of ICU patients who live is `r ci.lower` to `r ci.upper`.

###6.68

```{r}
p = 16/25
np = 25 * p; np
nq = 25 * (1 - p); nq
```
The sample size would not be large enough for the CLT to apply, as both $np$ and $n(p-1)$ must be $\geq$ 10.

###6.134

```{r}
fiber = NutritionStudy$Fiber
fiber.mean = mean(NutritionStudy$Fiber); fiber.mean
fiber.se = sd(fiber)/sqrt(length(fiber)); fiber.se
fiber.moe = fiber.se * 2; fiber.moe
fiber.lower = fiber.mean - fiber.moe; fiber.lower
fiber.upper = fiber.mean + fiber.moe; fiber.upper
```
To find a 95% confidence interval for the mean number of grams of fiber people eat in a day, we use the **NutritionStudy$Fiber** mean, and multiply its standard error by 2 to find our margin of error. Then we can find the upper and lower bounds by applying $mean \pm moe$. The average number of grams of fiber people eat in a day is between `r fiber.lower` grams and `r fiber.upper` grams.

###6.152

$H_0: \mu = 160; H_a: \mu > 160$
```{r}
dotplot(~Fouls, cex = 1.2, width = 0.2, data = NBAPlayers2011)
favstats(~Fouls, data = NBAPlayers2011)
p.value = pval(t.test(~Fouls, mu = 160, data = NBAPlayers2011)); p.value
```
Using our hypothesis, we are given a p-value of `r p.value`, which is $> 0.05$. Therefore, we accept the null hypothesis and reject that NBA players who play regularly have a mean number of fouls in a season greater than 160.
